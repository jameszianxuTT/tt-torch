name: Run Full Model Execution Tests

on:
  workflow_dispatch:
  workflow_call:
    inputs:
      docker-image:
        description: 'Docker image to use for build'
        required: true
        type: string
      run-codecov:
        description: 'Run code coverage reports'
        required: false
        type: string
        default: 'true'
      is_nightly:
        description: 'Set to "true" to run the full (common + nightly extra) test set'
        required: false
        type: string
        default: 'false'
  workflow_run:
    workflows: [Build]
    types: [completed]

###############################
# Job to generate the test matrix
###############################
jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: Generate matrix from full-model-execution-test-matrix.yml
        id: set-matrix
        shell: bash
        env:
          IS_NIGHTLY: ${{ inputs.is_nightly }}
        run: |
          MATRIX=$(python << 'EOF'
import yaml, json, os
with open("full-model-execution-test-matrix.yml", "r") as f:
    data = yaml.safe_load(f)
is_nightly = os.getenv("IS_NIGHTLY", "false").lower() == "true"
# Start with the common tests.
matrix = data["common_tests"]
# If nightly, add the extra tests.
if is_nightly:
    matrix.extend(data.get("nightly_extra", []))
print(json.dumps(matrix))
EOF
)
          echo "Selected matrix: $MATRIX"
          echo "::set-output name=matrix::$MATRIX"

###############################
# The tests job using the dynamic matrix.
###############################
  tests:
    needs: generate-matrix
    timeout-minutes: 60
    strategy:
      fail-fast: false
      matrix:
        build: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    runs-on: ${{ matrix.build["runs-on"] }}
    name: "test execution (${{ matrix.build.runs-on }}, ${{ matrix.build.name }})"
    container:
      image: ${{ inputs.docker-image }}
      options: --user root --device /dev/tenstorrent/0 --shm-size=4gb
      volumes:
        - /dev/hugepages:/dev/hugepages
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /etc/udev/rules.d:/etc/udev/rules.d
        - /lib/modules:/lib/modules
        - /opt/tt_metal_infra/provisioning/provisioning_env:/opt/tt_metal_infra/provisioning/provisioning_env
        - /mnt/dockercache:/mnt/dockercache
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
          lfs: true
      - name: Fetch job id
        id: fetch-job-id
        uses: tenstorrent/tt-github-actions/.github/actions/job_id@main
        with:
          job_name: "test execution (${{ matrix.build.runs-on }}, ${{ matrix.build.name }})"
      - name: Set reusable strings
        id: strings
        shell: bash
        env:
          JOB_ID: ${{ steps.fetch-job-id.outputs.job_id }}
        run: |
          echo "work-dir=$(pwd)" >> "$GITHUB_OUTPUT"
          echo "install-dir=$(pwd)/install" >> "$GITHUB_OUTPUT"
          echo "dist-dir=$(pwd)/dist" >> "$GITHUB_OUTPUT"
          echo "test_report_path_models=report_models_$JOB_ID.xml" >> "$GITHUB_OUTPUT"
      - name: Use build artifacts
        uses: actions/download-artifact@v4
        with:
          name: install-artifacts
          path: ${{ steps.strings.outputs.install-dir }}
      - name: Untar install directory
        shell: bash
        working-directory: ${{ steps.strings.outputs.install-dir }}
        run: |
          tar xvf artifact.tar
          mkdir -p ${{ steps.strings.outputs.dist-dir }}
          mv wheels/* ${{ steps.strings.outputs.dist-dir }}
      - name: install tt-torch
        shell: bash
        run: |
          source env/activate
          pip install ${{ steps.strings.outputs.dist-dir }}/*.whl
      - name: Run Full Model Execution Tests
        env:
          HF_HOME: /mnt/dockercache/huggingface
          TORCH_HOME: /mnt/dockercache/torch
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        shell: bash
        run: |
          source env/activate
          apt-get update
          apt install -y libgl1 libglx-mesa0
          pytest -v ${{ matrix.build.tests }} \
            --junit-xml=${{ steps.strings.outputs.test_report_path_models }} \
            --cov=tt_torch --cov-report term --cov-report xml:coverage.xml --cov-append
      - name: Upload Test Report Models
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-reports-models-${{ matrix.build.runs-on }}-${{ matrix.build.name }}-${{ steps.fetch-job-id.outputs.job_id }}
          path: ${{ steps.strings.outputs.test_report_path_models }}
      - name: Upload coverage reports to Codecov
        if: ${{ (success() || failure()) && inputs.run-codecov == 'true' }}
        continue-on-error: true
        uses: codecov/codecov-action@v5
        with:
          files: coverage.info,.coverage,coverage.xml
          token: ${{ secrets.CODECOV_TOKEN }}
      - name: Upload test results to Codecov
        if: ${{ (success() || failure()) && inputs.run-codecov == 'true' }}
        continue-on-error: true
        uses: codecov/test-results-action@v1
        with:
          files: ${{ steps.strings.outputs.test_report_path_models }}
          disable_search: true
          token: ${{ secrets.CODECOV_TOKEN }}
